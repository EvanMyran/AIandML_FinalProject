{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079},{"sourceId":61859,"sourceType":"datasetVersion","datasetId":39899}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Evan Myran and Andrew Martens Final Project for CS380 AI and Machine Learning.\nThis program trains a model on data sets of ASL letters and can accurately interpret images of ASL signings and report the correct lettered signed to the user. ","metadata":{}},{"cell_type":"code","source":"#IMPORTS\n#system set up\nimport sys\n\nassert sys.version_info >= (3, 7)\n\nfrom packaging import version\nimport sklearn\n\nassert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n\nimport matplotlib.pyplot as plt\n\n#pretty plots!!!!\nplt.rc('font', size=14)\nplt.rc('axes', labelsize=14, titlesize=14)\nplt.rc('legend', fontsize=14)\nplt.rc('xtick', labelsize=10)\nplt.rc('ytick', labelsize=10)\n\nimport numpy as np \nassert version.parse(np.__version__) >= version.parse(\"1.22.0\")\n\n#Tensorflow imports\nimport pandas as pd\nimport pathlib\nfrom pathlib import Path\nfrom matplotlib.pyplot import imread\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nimport keras\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom keras.utils import image_dataset_from_directory\n\n# Imports for Deep Learning\nfrom keras import layers\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, InputLayer\nfrom keras.models import Sequential\n\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\n\nfrom keras.utils import to_categorical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-26T18:33:50.690218Z","iopub.execute_input":"2024-01-26T18:33:50.690563Z","iopub.status.idle":"2024-01-26T18:34:05.887849Z","shell.execute_reply.started":"2024-01-26T18:33:50.690534Z","shell.execute_reply":"2024-01-26T18:34:05.886997Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Import Data**\n\nAdding directories for train and test set, then loading using image_dataset_from_directory","metadata":{}},{"cell_type":"code","source":"#variables for the directories of our train and test sets\n#the basis for our training and valid set is the train_dir\ntrain_dir = \"../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/\" # A/A1.jpg\ntest_dir = \"../input/asl-alphabet-test/asl-alphabet-test\"","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:05.889465Z","iopub.execute_input":"2024-01-26T18:34:05.889992Z","iopub.status.idle":"2024-01-26T18:34:05.894726Z","shell.execute_reply.started":"2024-01-26T18:34:05.889964Z","shell.execute_reply":"2024-01-26T18:34:05.893576Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#create our train, valid, and test sets from our imported data\ntrain_data = image_dataset_from_directory(train_dir, labels='inferred', image_size=(200,200), seed=123, validation_split=.2, subset='training')\nvalid_data = image_dataset_from_directory(train_dir, labels='inferred', image_size=(200,200), seed=123, validation_split=.2, subset='validation')\ntest_data = image_dataset_from_directory(test_dir, labels='inferred', image_size=(200,200), seed=123)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:05.896079Z","iopub.execute_input":"2024-01-26T18:34:05.896446Z","iopub.status.idle":"2024-01-26T18:35:10.741636Z","shell.execute_reply.started":"2024-01-26T18:34:05.896414Z","shell.execute_reply":"2024-01-26T18:35:10.740840Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Attempt to load test data to numpy arrays** \n\nConvert our batch datasets to numpy arrays to split our data into x and y sets.","metadata":{}},{"cell_type":"code","source":"# TEST SET\n#break our test_data into x and y values\nfor images, labels in test_data:\n    X_test = images.numpy()\n    y_test = labels.numpy()\n    break\nprint(X_test.shape)\ny_test","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:35:10.744245Z","iopub.execute_input":"2024-01-26T18:35:10.744625Z","iopub.status.idle":"2024-01-26T18:35:11.103530Z","shell.execute_reply.started":"2024-01-26T18:35:10.744591Z","shell.execute_reply":"2024-01-26T18:35:11.101611Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TRAIN SET\n#break our test_data into x and y values\nfor images, labels in train_data:\n    X_train = images.numpy()\n    y_train = labels.numpy()\n    break\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:35:11.105395Z","iopub.execute_input":"2024-01-26T18:35:11.105875Z","iopub.status.idle":"2024-01-26T18:35:11.673741Z","shell.execute_reply.started":"2024-01-26T18:35:11.105826Z","shell.execute_reply":"2024-01-26T18:35:11.672710Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Visualize Data**\n\nDisplay our images so we can get an idea with what our data looks like","metadata":{}},{"cell_type":"code","source":"class_names = train_data.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_data.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:35:11.675155Z","iopub.execute_input":"2024-01-26T18:35:11.675522Z","iopub.status.idle":"2024-01-26T18:35:13.242943Z","shell.execute_reply.started":"2024-01-26T18:35:11.675487Z","shell.execute_reply":"2024-01-26T18:35:13.241933Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Convolutional Neural Network**\n\nBuild our network and layers","metadata":{}},{"cell_type":"code","source":"#Sequential model\nmodel = Sequential()\n#input layer, define shape\nmodel.add(layers.Input(shape=(200,200,3)))\n#layer to rescale our images\nmodel.add(layers.Rescaling(1./255)),\n#convultion layer\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n#pooling layer for the images\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(29, activation='softmax'))\n\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n\n#print summary of our model and layers\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:35:13.244336Z","iopub.execute_input":"2024-01-26T18:35:13.244611Z","iopub.status.idle":"2024-01-26T18:35:13.438090Z","shell.execute_reply.started":"2024-01-26T18:35:13.244587Z","shell.execute_reply":"2024-01-26T18:35:13.437134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Train Model**\n\nRun train and valid data through the model with 5 epochs","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_data, epochs=10, validation_data=valid_data)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:35:13.439417Z","iopub.execute_input":"2024-01-26T18:35:13.439801Z","iopub.status.idle":"2024-01-26T18:52:52.279916Z","shell.execute_reply.started":"2024-01-26T18:35:13.439767Z","shell.execute_reply":"2024-01-26T18:52:52.279026Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Plot Accuracy and Loss**","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(10)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:56:45.136239Z","iopub.execute_input":"2024-01-26T18:56:45.136674Z","iopub.status.idle":"2024-01-26T18:56:45.638659Z","shell.execute_reply.started":"2024-01-26T18:56:45.136623Z","shell.execute_reply":"2024-01-26T18:56:45.637650Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Testing Our Model**\n\nPredict the ASL sign based our test images","metadata":{}},{"cell_type":"code","source":"import matplotlib.image as mpimg\n\n\n#array of all images in colab with corresponding label\nimg_array = [\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/A_test.jpg\", 'A'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/B_test.jpg\", 'B'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/C_test.jpg\",'C'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/D_test.jpg\", 'D'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/E_test.jpg\", 'E'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/F_test.jpg\", 'F'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/G_test.jpg\", 'G'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/H_test.jpg\", 'H'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/I_test.jpg\", 'I'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/J_test.jpg\", 'J'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/K_test.jpg\", 'K'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/L_test.jpg\", 'L'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/M_test.jpg\", 'M'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/N_test.jpg\", 'N'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/O_test.jpg\", 'O'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/P_test.jpg\", 'P'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/Q_test.jpg\", 'Q'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/R_test.jpg\", 'R'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/S_test.jpg\", 'S'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/T_test.jpg\", 'T'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/U_test.jpg\", 'U'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/V_test.jpg\", 'V'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/W_test.jpg\", 'W'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/X_test.jpg\", 'X'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/Y_test.jpg\", 'Y'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/Z_test.jpg\", 'Z'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/nothing_test.jpg\", 'nothing'],\n    [\"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/space_test.jpg\", 'space']]\n\n#for loop to iterate through image name array and print predictions\nfor i, label in img_array:\n    test_path = i\n    img = keras.utils.load_img(test_path, target_size=(200, 200))\n    x = keras.utils.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    # model makes prediction on the image\n    preds = model.predict(x)\n\n    #get the predicted class index\n    predicted_class_index = np.argmax(preds[0])\n    predicted_class_label = class_names[predicted_class_index]\n    \n    # displays the image\n    image = mpimg.imread(test_path)\n    plt.imshow(image)\n    plt.title('Actual Class: '+label+' - Predicted Class: '+predicted_class_label)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:56:49.678355Z","iopub.execute_input":"2024-01-26T18:56:49.678734Z","iopub.status.idle":"2024-01-26T18:56:58.367077Z","shell.execute_reply.started":"2024-01-26T18:56:49.678705Z","shell.execute_reply":"2024-01-26T18:56:58.366095Z"},"trusted":true},"outputs":[],"execution_count":null}]}